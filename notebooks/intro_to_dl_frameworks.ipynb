{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Open_source_DL_frameworks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ContinualAI/colab/blob/master/intro_to_DL_frameworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dF-JFhOG1pyH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Open-Source Frameworks for Deep Learning: an Overview\n",
        "\n",
        "\n",
        "This notebook is part of the 2 hrs talk given at the Univerity of Bologna (DISI), Nuovo Campus Universitario, Via Pavese 50, Cesena, FC the 13th of December 2018, 10-12 am. Remember to include the copyright if you want to use, modify or distribute this notebook! :-) Slides of the talk are available [here](https://docs.google.com/presentation/d/1fbTKtp9xOlCL4JtpiLF39x7Vxq2Z-jgn77CTqcBrwEE/edit?usp=sharing).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "R2jITHxjvZx7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Abstract** : The rise of deep learning over the last decade has led to profound changes in the landscape of the machine learning software stack both for research and production. In this talk we will provide a comprehensive overview of the *open-source deep learning frameworks* landscape with both a theoretical and hands-on approach. After a brief introduction and historical contextualization, we will highlight common features and distinctions of their recent developments. Finally, we will take at deeper look into three of the most used deep learning frameworks today: *Caffe*, *Tensorflow*, *PyTorch*; with practical examples and considerations worth reckoning in the choice of such libraries.\n",
        "\n",
        "**Short Bio** : [Vincenzo Lomonaco](https://vincenzolomonaco.com) is a Deep Learning PhD student at the University of Bologna and founder of [ContinualAI.org](https://continualai.org). He is also the PhD students representative at the Department of Computer Science of Engineering (DISI) and teaching assistant of the courses *“Machine Learning”* and *“Computer Architectures”* in the same department. Previously, he was a Machine Learning software engineer at IDL in-line Devices and a Master Student at the University of Bologna where he graduated cum laude in 2015 with the dissertation [“Deep Learning for Computer Vision: a Comparison Between CNNs and HTMs on Object Recognition Tasks\"](https://amslaurea.unibo.it/9095/).\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "3pJ2xB48pjgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Connecting a local runtime**\n",
        "\n",
        "In case resources are not enough for you (no GPU for example), you can always connect another [local runtime](https://research.google.com/colaboratory/local-runtimes.html) or to a [runtime on a Google Compute Engine instance](https://research.google.com/colaboratory/local-runtimes.html). However, this notebook has been designed to run fast enough on simple CPUs so you shouldn't fined any trouble here, using a free *hosted account*.\n",
        "\n",
        "\n",
        "**Requisites to run it locally, outside colab (not recommended)**\n",
        "\n",
        "*   Python 3.x\n",
        "*   Jupyter\n",
        "*   Numpy\n",
        "*   Matplolib\n",
        "*   Pytorch 0.4.0\n",
        "*   Caffe 1.0.0\n",
        "*  Tensorflow 1.12"
      ]
    },
    {
      "metadata": {
        "id": "Bg1m-mau3nim",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hands-on session (45 minutes)\n",
        "\n",
        "In this session we will try to learn an evaluate a Convolutional Neural Networks model on [MNIST](http://yann.lecun.com/exdb/mnist/) using three of the most used deep learning frameworks today: *Caffe*, *Tensorflow*, *PyTorch* with an expected timeframe of 15 minutes for each of them. This will allow us to grasp what it means to train a deep model with such libraries and compare the different Python APIs for this simple use case."
      ]
    },
    {
      "metadata": {
        "id": "GD97xBZTgyjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "First of all, take a moment to look around and discover Google Colab if you haven't before! You can run the commands below to understand how much resources you're using and are still available. Then consider also that you can also connect you Google Drive for additional space or for easily loading your own files. Check out the [official tutorial](https://colab.research.google.com/) of the Google Colaboratory for more information.\n",
        "\n",
        "You can always reset the entire VM with \"*Runtime > Reset all runtime*\" in case of difficulty. Make also sure you're using the GPU or TPU in the same tab (\"*Runtime > Change runtime type*\")."
      ]
    },
    {
      "metadata": {
        "id": "AmbdpXfPhBeA",
        "colab_type": "code",
        "outputId": "be22427c-e2c6-4efe-898e-e48ae35ba438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "!free -m\n",
        "!df -h\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13022         413       10941           0        1668       12343\n",
            "Swap:             0           0           0\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G   17G  324G   5% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G  8.0K  6.4G   1% /var/colab\n",
            "/dev/sda1       365G   21G  345G   6% /opt/bin\n",
            "shm             6.0G     0  6.0G   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "Wed Dec 12 15:16:01 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M0VsdEjmhEY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Questions to explore:\n",
        "\n",
        "*   How to connect your Google Drive with Google Colab?\n",
        "*   How to import a new notebook and save it to your GDrive?\n",
        "*  How to use files which are contained in your GDrive?\n",
        "\n",
        "Some tips here: https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
      ]
    },
    {
      "metadata": {
        "id": "tDvwfvb9hGvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the MNIST Benchamark"
      ]
    },
    {
      "metadata": {
        "id": "_SbJJIUenz07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "in this section we load the common MNIST benchmark which we will use for our examples. We will take advantage of the *ContinualAI* calab scripts for easy loading of the MNIST images as numpy tensors:"
      ]
    },
    {
      "metadata": {
        "id": "7VdJOCNYbYu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5RB5PMdbDNx",
        "colab_type": "code",
        "outputId": "26de3dfa-cb73-4cc8-8deb-23a85f7a5fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'continualai/colab'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 74 (delta 23), reused 19 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BD0nAldMbD5O",
        "colab_type": "code",
        "outputId": "2c81ceef-c5c1-46d4-b0cf-ced531bb717b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from continualai.colab.scripts import mnist\n",
        "mnist.init()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Download complete.\n",
            "Save complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S4cSFTbcbKeb",
        "colab_type": "code",
        "outputId": "edcdbac6-4299-4918-a280-463b2c89bbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\n",
        "\n",
        "print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n",
        "print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n",
        "print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n",
        "print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train dim and type:  (60000, 1, 28, 28) float32\n",
            "t_train dim and type:  (60000,) uint8\n",
            "x_test dim and type:  (10000, 1, 28, 28) float32\n",
            "t_test dim and type:  (10000,) uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5h1yw26KrRUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us take a look at these images:"
      ]
    },
    {
      "metadata": {
        "id": "A1PMSnyNbNxr",
        "colab_type": "code",
        "outputId": "52235bcd-66ce-497e-df43-b97d866082ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\n",
        "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\n",
        "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFLCAYAAADiejquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efeb90e4a58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7ajRYeYGBWm8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Common Constants"
      ]
    },
    {
      "metadata": {
        "id": "H5neMaipojPP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can move on and define some common constants that we will share across the DL framework experiments:"
      ]
    },
    {
      "metadata": {
        "id": "UZwum8trBbJf",
        "colab_type": "code",
        "outputId": "64763d56-b741-49d6-ec10-21b58c342dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# we will use time to measure speed\n",
        "import time\n",
        "\n",
        "# number of classes in the MNIST dataset\n",
        "num_class = 10\n",
        "\n",
        "# number of epochs we will use for each training\n",
        "n_epochs = 2\n",
        "\n",
        "# mini-batch size for SGD\n",
        "minibatch_size = 100\n",
        "\n",
        "# Iterations for epoch for the two sets\n",
        "tr_it_for_epoch = t_train.shape[0] // minibatch_size\n",
        "te_it_for_epoch = t_test.shape[0] // minibatch_size\n",
        "print(\"train iterations: \", tr_it_for_epoch)\n",
        "print(\"test iterations: \", te_it_for_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train iterations:  600\n",
            "test iterations:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yDYuMadt28ET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a ConvNet with Caffe\n",
        "\n",
        "Let us focus on *Caffe*. First of all let us install the library. Luckily enough for Ubuntu (>= 17.04) there is a packaged version we can install simply with:"
      ]
    },
    {
      "metadata": {
        "id": "Nv28V1_g1jeB",
        "colab_type": "code",
        "outputId": "65987491-dc47-4f22-acfe-4c5cb6691a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6465
        }
      },
      "cell_type": "code",
      "source": [
        "# !apt install -y caffe-cpu\n",
        "!apt install -y caffe-cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libgflags2.2\n",
            "  libgoogle-glog0v5 libjs-jquery libjs-jquery-ui libleveldb1v5 liblmdb0\n",
            "  libyaml-0-2 python-matplotlib-data python-tables-data python3-bs4\n",
            "  python3-caffe-cuda python3-chardet python3-cycler python3-dateutil\n",
            "  python3-decorator python3-gflags python3-h5py python3-html5lib\n",
            "  python3-ipython python3-ipython-genutils python3-leveldb python3-matplotlib\n",
            "  python3-networkx python3-nose python3-numexpr python3-pandas\n",
            "  python3-pandas-lib python3-pexpect python3-pickleshare python3-pkg-resources\n",
            "  python3-prompt-toolkit python3-protobuf python3-ptyprocess python3-pygments\n",
            "  python3-pyparsing python3-pywt python3-scipy python3-simplegeneric\n",
            "  python3-six python3-skimage python3-skimage-lib python3-tables\n",
            "  python3-tables-lib python3-traitlets python3-tz python3-wcwidth\n",
            "  python3-webencodings python3-yaml ttf-bitstream-vera\n",
            "Suggested packages:\n",
            "  libcaffe-cuda-dev caffe-doc cython-doc apache2 | lighttpd | httpd\n",
            "  libjs-jquery-ui-docs python-cycler-doc python-h5py-doc python3-genshi dvipng\n",
            "  gir1.2-gtk-3.0 ghostscript inkscape ipython3 python-matplotlib-doc\n",
            "  python3-cairocffi python3-gi-cairo python3-gobject python3-pyqt4 python3-sip\n",
            "  python3-tornado texlive-extra-utils texlive-latex-extra ttf-staypuft\n",
            "  python-nose-doc python-pandas-doc python-pexpect-doc python3-setuptools\n",
            "  python-pyparsing-doc python-scipy-doc python-skimage-doc python-tables-doc\n",
            "  python3-netcdf4 vitables\n",
            "Recommended packages:\n",
            "  libcuda1 | libcuda-9.1-1\n",
            "The following NEW packages will be installed:\n",
            "  caffe-cuda caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libgflags2.2\n",
            "  libgoogle-glog0v5 libjs-jquery libjs-jquery-ui libleveldb1v5 liblmdb0\n",
            "  libyaml-0-2 python-matplotlib-data python-tables-data python3-bs4\n",
            "  python3-caffe-cuda python3-chardet python3-cycler python3-dateutil\n",
            "  python3-decorator python3-gflags python3-h5py python3-html5lib\n",
            "  python3-ipython python3-ipython-genutils python3-leveldb python3-matplotlib\n",
            "  python3-networkx python3-nose python3-numexpr python3-pandas\n",
            "  python3-pandas-lib python3-pexpect python3-pickleshare python3-pkg-resources\n",
            "  python3-prompt-toolkit python3-protobuf python3-ptyprocess python3-pygments\n",
            "  python3-pyparsing python3-pywt python3-scipy python3-simplegeneric\n",
            "  python3-six python3-skimage python3-skimage-lib python3-tables\n",
            "  python3-tables-lib python3-traitlets python3-tz python3-wcwidth\n",
            "  python3-webencodings python3-yaml ttf-bitstream-vera\n",
            "0 upgraded, 59 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 119 MB of archives.\n",
            "After this operation, 310 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libyaml-0-2 amd64 0.1.7-2ubuntu3 [47.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-yaml amd64 3.12-1build2 [109 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcublas9.1 amd64 9.1.85-3ubuntu1 [25.0 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcudart9.1 amd64 9.1.85-3ubuntu1 [121 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcurand9.1 amd64 9.1.85-3ubuntu1 [38.9 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags2.2 amd64 2.2.1-1 [72.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog0v5 amd64 0.3.5-1 [50.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb1v5 amd64 1.20-2 [136 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblmdb0 amd64 0.9.21-1 [43.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcaffe-cuda1 amd64 1.0.0-6build1 [1,600 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 caffe-tools-cuda amd64 1.0.0-6build1 [105 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cython3 amd64 0.26.1-0.4 [1,925 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-dateutil all 2.6.1-1 [52.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-gflags all 1.5.1-5 [35.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-h5py amd64 2.7.1-2 [631 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-decorator all 4.1.2-1 [9,364 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-ptyprocess all 0.5.2-1 [12.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pexpect all 4.2.1-1 [42.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pickleshare all 0.7.4-2 [6,904 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wcwidth all 0.1.7+dfsg1-1 [14.7 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-prompt-toolkit all 1.0.15-1 [163 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pygments all 2.2.0+dfsg-1 [574 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-simplegeneric all 0.8.1-1 [11.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython-genutils all 0.2.0-1 [20.9 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-traitlets all 4.3.2-1 [59.1 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython all 5.5.0-1 [381 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-leveldb amd64 0~svn68-3build3 [18.3 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-lyx all 2.2.3-5 [155 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ttf-bitstream-vera all 1.10-8 [352 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-matplotlib-data all 2.1.1-2ubuntu3 [3,774 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pyparsing all 2.2.0+dfsg1-2 [52.2 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-tz all 2018.3-2 [25.1 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjs-jquery-ui all 1.12.1+dfsg-5 [232 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-cycler all 0.10.0-1 [7,622 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-matplotlib amd64 2.1.1-2ubuntu3 [3,907 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-networkx all 1.11-1ubuntu2 [606 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-nose all 1.3.7-3 [115 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pandas-lib amd64 0.22.0-4 [3,041 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pandas all 0.22.0-4 [2,764 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-protobuf amd64 3.0.0-9.1ubuntu1 [262 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-scipy amd64 0.19.1-2ubuntu1 [9,619 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage-lib amd64 0.13.1-2 [1,504 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pywt amd64 0.5.1-1.1ubuntu4 [932 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage all 0.13.1-2 [19.6 MB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 python3-caffe-cuda amd64 1.0.0-6build1 [689 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 caffe-cuda amd64 1.0.0-6build1 [4,564 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libblosc1 amd64 1.14.2+ds1-1 [31.4 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-tables-data all 3.4.2-4 [46.1 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-bs4 all 4.6.0-1 [67.8 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-webencodings all 0.5-2 [10.4 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-html5lib all 0.999999999-1 [81.9 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-numexpr amd64 2.6.4-1 [119 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-tables-lib amd64 3.4.2-4 [413 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-tables all 3.4.2-4 [331 kB]\n",
            "Fetched 119 MB in 3s (45.5 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libyaml-0-2:amd64.\n",
            "(Reading database ... 110377 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libyaml-0-2_0.1.7-2ubuntu3_amd64.deb ...\n",
            "Unpacking libyaml-0-2:amd64 (0.1.7-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-yaml.\n",
            "Preparing to unpack .../01-python3-yaml_3.12-1build2_amd64.deb ...\n",
            "Unpacking python3-yaml (3.12-1build2) ...\n",
            "Selecting previously unselected package libcublas9.1:amd64.\n",
            "Preparing to unpack .../02-libcublas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcudart9.1:amd64.\n",
            "Preparing to unpack .../03-libcudart9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcurand9.1:amd64.\n",
            "Preparing to unpack .../04-libcurand9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "Preparing to unpack .../05-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../06-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../07-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../08-liblmdb0_0.9.21-1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1) ...\n",
            "Selecting previously unselected package libcaffe-cuda1:amd64.\n",
            "Preparing to unpack .../09-libcaffe-cuda1_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-tools-cuda.\n",
            "Preparing to unpack .../10-caffe-tools-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package cython3.\n",
            "Preparing to unpack .../11-cython3_0.26.1-0.4_amd64.deb ...\n",
            "Unpacking cython3 (0.26.1-0.4) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../12-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-dateutil.\n",
            "Preparing to unpack .../13-python3-dateutil_2.6.1-1_all.deb ...\n",
            "Unpacking python3-dateutil (2.6.1-1) ...\n",
            "Selecting previously unselected package python3-gflags.\n",
            "Preparing to unpack .../14-python3-gflags_1.5.1-5_all.deb ...\n",
            "Unpacking python3-gflags (1.5.1-5) ...\n",
            "Selecting previously unselected package python3-h5py.\n",
            "Preparing to unpack .../15-python3-h5py_2.7.1-2_amd64.deb ...\n",
            "Unpacking python3-h5py (2.7.1-2) ...\n",
            "Selecting previously unselected package python3-decorator.\n",
            "Preparing to unpack .../16-python3-decorator_4.1.2-1_all.deb ...\n",
            "Unpacking python3-decorator (4.1.2-1) ...\n",
            "Selecting previously unselected package python3-ptyprocess.\n",
            "Preparing to unpack .../17-python3-ptyprocess_0.5.2-1_all.deb ...\n",
            "Unpacking python3-ptyprocess (0.5.2-1) ...\n",
            "Selecting previously unselected package python3-pexpect.\n",
            "Preparing to unpack .../18-python3-pexpect_4.2.1-1_all.deb ...\n",
            "Unpacking python3-pexpect (4.2.1-1) ...\n",
            "Selecting previously unselected package python3-pickleshare.\n",
            "Preparing to unpack .../19-python3-pickleshare_0.7.4-2_all.deb ...\n",
            "Unpacking python3-pickleshare (0.7.4-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../20-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wcwidth.\n",
            "Preparing to unpack .../21-python3-wcwidth_0.1.7+dfsg1-1_all.deb ...\n",
            "Unpacking python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Selecting previously unselected package python3-prompt-toolkit.\n",
            "Preparing to unpack .../22-python3-prompt-toolkit_1.0.15-1_all.deb ...\n",
            "Unpacking python3-prompt-toolkit (1.0.15-1) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../23-python3-pygments_2.2.0+dfsg-1_all.deb ...\n",
            "Unpacking python3-pygments (2.2.0+dfsg-1) ...\n",
            "Selecting previously unselected package python3-simplegeneric.\n",
            "Preparing to unpack .../24-python3-simplegeneric_0.8.1-1_all.deb ...\n",
            "Unpacking python3-simplegeneric (0.8.1-1) ...\n",
            "Selecting previously unselected package python3-ipython-genutils.\n",
            "Preparing to unpack .../25-python3-ipython-genutils_0.2.0-1_all.deb ...\n",
            "Unpacking python3-ipython-genutils (0.2.0-1) ...\n",
            "Selecting previously unselected package python3-traitlets.\n",
            "Preparing to unpack .../26-python3-traitlets_4.3.2-1_all.deb ...\n",
            "Unpacking python3-traitlets (4.3.2-1) ...\n",
            "Selecting previously unselected package python3-ipython.\n",
            "Preparing to unpack .../27-python3-ipython_5.5.0-1_all.deb ...\n",
            "Unpacking python3-ipython (5.5.0-1) ...\n",
            "Selecting previously unselected package python3-leveldb.\n",
            "Preparing to unpack .../28-python3-leveldb_0~svn68-3build3_amd64.deb ...\n",
            "Unpacking python3-leveldb (0~svn68-3build3) ...\n",
            "Selecting previously unselected package fonts-lyx.\n",
            "Preparing to unpack .../29-fonts-lyx_2.2.3-5_all.deb ...\n",
            "Unpacking fonts-lyx (2.2.3-5) ...\n",
            "Selecting previously unselected package ttf-bitstream-vera.\n",
            "Preparing to unpack .../30-ttf-bitstream-vera_1.10-8_all.deb ...\n",
            "Unpacking ttf-bitstream-vera (1.10-8) ...\n",
            "Selecting previously unselected package python-matplotlib-data.\n",
            "Preparing to unpack .../31-python-matplotlib-data_2.1.1-2ubuntu3_all.deb ...\n",
            "Unpacking python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-pyparsing.\n",
            "Preparing to unpack .../32-python3-pyparsing_2.2.0+dfsg1-2_all.deb ...\n",
            "Unpacking python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Selecting previously unselected package python3-tz.\n",
            "Preparing to unpack .../33-python3-tz_2018.3-2_all.deb ...\n",
            "Unpacking python3-tz (2018.3-2) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../34-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libjs-jquery-ui.\n",
            "Preparing to unpack .../35-libjs-jquery-ui_1.12.1+dfsg-5_all.deb ...\n",
            "Unpacking libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Selecting previously unselected package python3-cycler.\n",
            "Preparing to unpack .../36-python3-cycler_0.10.0-1_all.deb ...\n",
            "Unpacking python3-cycler (0.10.0-1) ...\n",
            "Selecting previously unselected package python3-matplotlib.\n",
            "Preparing to unpack .../37-python3-matplotlib_2.1.1-2ubuntu3_amd64.deb ...\n",
            "Unpacking python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-networkx.\n",
            "Preparing to unpack .../38-python3-networkx_1.11-1ubuntu2_all.deb ...\n",
            "Unpacking python3-networkx (1.11-1ubuntu2) ...\n",
            "Selecting previously unselected package python3-nose.\n",
            "Preparing to unpack .../39-python3-nose_1.3.7-3_all.deb ...\n",
            "Unpacking python3-nose (1.3.7-3) ...\n",
            "Selecting previously unselected package python3-pandas-lib.\n",
            "Preparing to unpack .../40-python3-pandas-lib_0.22.0-4_amd64.deb ...\n",
            "Unpacking python3-pandas-lib (0.22.0-4) ...\n",
            "Selecting previously unselected package python3-pandas.\n",
            "Preparing to unpack .../41-python3-pandas_0.22.0-4_all.deb ...\n",
            "Unpacking python3-pandas (0.22.0-4) ...\n",
            "Selecting previously unselected package python3-protobuf.\n",
            "Preparing to unpack .../42-python3-protobuf_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package python3-scipy.\n",
            "Preparing to unpack .../43-python3-scipy_0.19.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-skimage-lib:amd64.\n",
            "Preparing to unpack .../44-python3-skimage-lib_0.13.1-2_amd64.deb ...\n",
            "Unpacking python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-pywt.\n",
            "Preparing to unpack .../45-python3-pywt_0.5.1-1.1ubuntu4_amd64.deb ...\n",
            "Unpacking python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Selecting previously unselected package python3-skimage.\n",
            "Preparing to unpack .../46-python3-skimage_0.13.1-2_all.deb ...\n",
            "Unpacking python3-skimage (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-caffe-cuda.\n",
            "Preparing to unpack .../47-python3-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-cuda.\n",
            "Preparing to unpack .../48-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../49-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libblosc1.\n",
            "Preparing to unpack .../50-libblosc1_1.14.2+ds1-1_amd64.deb ...\n",
            "Unpacking libblosc1 (1.14.2+ds1-1) ...\n",
            "Selecting previously unselected package python-tables-data.\n",
            "Preparing to unpack .../51-python-tables-data_3.4.2-4_all.deb ...\n",
            "Unpacking python-tables-data (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-bs4.\n",
            "Preparing to unpack .../52-python3-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python3-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../53-python3-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python3-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python3-webencodings.\n",
            "Preparing to unpack .../54-python3-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python3-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python3-html5lib.\n",
            "Preparing to unpack .../55-python3-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python3-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python3-numexpr.\n",
            "Preparing to unpack .../56-python3-numexpr_2.6.4-1_amd64.deb ...\n",
            "Unpacking python3-numexpr (2.6.4-1) ...\n",
            "Selecting previously unselected package python3-tables-lib.\n",
            "Preparing to unpack .../57-python3-tables-lib_3.4.2-4_amd64.deb ...\n",
            "Unpacking python3-tables-lib (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-tables.\n",
            "Preparing to unpack .../58-python3-tables_3.4.2-4_all.deb ...\n",
            "Unpacking python3-tables (3.4.2-4) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libblosc1 (1.14.2+ds1-1) ...\n",
            "Setting up python3-pickleshare (0.7.4-2) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up python3-simplegeneric (0.8.1-1) ...\n",
            "Setting up python3-webencodings (0.5-2) ...\n",
            "Setting up python3-tables-lib (3.4.2-4) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Setting up python3-cycler (0.10.0-1) ...\n",
            "Setting up python-tables-data (3.4.2-4) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-bs4 (4.6.0-1) ...\n",
            "Setting up python3-gflags (1.5.1-5) ...\n",
            "update-alternatives: using /usr/bin/python3-gflags2man to provide /usr/bin/gflags2man (gflags2man) in auto mode\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Setting up python3-pandas-lib (0.22.0-4) ...\n",
            "Setting up python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Setting up libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libyaml-0-2:amd64 (0.1.7-2ubuntu3) ...\n",
            "Setting up python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up python3-ipython-genutils (0.2.0-1) ...\n",
            "Setting up python3-nose (1.3.7-3) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up python3-chardet (3.0.4-1) ...\n",
            "Setting up python3-html5lib (0.999999999-1) ...\n",
            "Setting up libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Setting up libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up ttf-bitstream-vera (1.10-8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up cython3 (0.26.1-0.4) ...\n",
            "Setting up python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Setting up libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python3-decorator (4.1.2-1) ...\n",
            "Setting up python3-traitlets (4.3.2-1) ...\n",
            "Setting up python3-ptyprocess (0.5.2-1) ...\n",
            "Setting up python3-tz (2018.3-2) ...\n",
            "Setting up python3-leveldb (0~svn68-3build3) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Setting up python3-dateutil (2.6.1-1) ...\n",
            "Setting up python3-h5py (2.7.1-2) ...\n",
            "Setting up fonts-lyx (2.2.3-5) ...\n",
            "Setting up python3-pygments (2.2.0+dfsg-1) ...\n",
            "Setting up python3-yaml (3.12-1build2) ...\n",
            "Setting up libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Setting up python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Setting up python3-prompt-toolkit (1.0.15-1) ...\n",
            "Setting up python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-numexpr (2.6.4-1) ...\n",
            "Setting up python3-tables (3.4.2-4) ...\n",
            "Setting up python3-pexpect (4.2.1-1) ...\n",
            "Setting up python3-networkx (1.11-1ubuntu2) ...\n",
            "Setting up python3-pandas (0.22.0-4) ...\n",
            "Setting up caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Setting up python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-ipython (5.5.0-1) ...\n",
            "Setting up python3-skimage (0.13.1-2) ...\n",
            "Setting up python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Setting up caffe-cuda (1.0.0-6build1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "333yU5z36lHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us now import the library and check the version:"
      ]
    },
    {
      "metadata": {
        "id": "K1BEnLBJ6NRh",
        "colab_type": "code",
        "outputId": "9e66e3c6-5f03-45cf-8cc4-c0a3a54eb6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import caffe\n",
        "caffe.__version__\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "8sKZwmcTr2TO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can set the hardware type:"
      ]
    },
    {
      "metadata": {
        "id": "WIZ-69f76pwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#caffe.set_mode_cpu()\n",
        "caffe.set_device(0)\n",
        "caffe.set_mode_gpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsLmtuS2sMd5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great! Now that we have caffe imported and configured, we can focus on the definition of our ConvNet and the training/testing procedures. The easiest way to define the network structure and the opimization parameters is to define two separate prototxts files. In this case we I have already prepared the net.prototxt and solver.prototxt files which we can import front the *ContinualAI-colab* toolchain:"
      ]
    },
    {
      "metadata": {
        "id": "7UaKFXZTT1yL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp continualai/colab/extras/net.prototxt .\n",
        "!cp continualai/colab/extras/solver.prototxt .\n",
        "solver_name = \"solver.prototxt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3H7t8awnaax3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before moving on let's visualize them with the awesome netscope tool: \n",
        "\n",
        "*   [net.prototxt](http://ethereon.github.io/netscope/#/gist/fbc84e148391c5bd953a5ec7d613b0f9)\n",
        "*   [solver.prototxt](https://gist.github.com/vlomonaco/82dbff5eab77e146b489d27a5cd5923f)"
      ]
    },
    {
      "metadata": {
        "id": "i7AZnMtEw1_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can define our test method:"
      ]
    },
    {
      "metadata": {
        "id": "juaaT4w2Kexo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(net, x, y, test_iters, test_batch_size, num_class):\n",
        "    \"\"\" test the trained net \"\"\"\n",
        "\n",
        "    acc = 0\n",
        "    loss = 0\n",
        "    for it in range(test_iters):\n",
        "        if it % 100 == 1: print(\"+\", end=\"\", flush = True)\n",
        "        start = it * test_batch_size\n",
        "        end = (it + 1) * test_batch_size\n",
        "        net.blobs['data'].data[...] = x[start:end]\n",
        "        net.blobs['label'].data[...] = y[start:end]\n",
        "        \n",
        "        out_layer = net._layer_names[-2]\n",
        "        blobs = net.forward([\"accuracy\", \"loss\"])\n",
        "        acc += blobs[\"accuracy\"]\n",
        "        loss += blobs[\"loss\"]\n",
        "\n",
        "    return acc / test_iters, loss / test_iters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBejsywww7MJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the solver and start the training procedure:"
      ]
    },
    {
      "metadata": {
        "id": "nouIQYHMbo4t",
        "colab_type": "code",
        "outputId": "d1325750-3cef-495f-fe10-c330b0694101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "solver = caffe.get_solver(solver_name)\n",
        "\n",
        "t_start = time.time()\n",
        "print(\"Start Training\")\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  print(\"Epoch\", epoch, \" \", end=\"\")\n",
        "  for it in range(tr_it_for_epoch):\n",
        "\n",
        "    if it % 100 == 1: print(\".\", end=\"\", flush=True)   \n",
        "    start = it * minibatch_size\n",
        "    end = (it + 1) * minibatch_size\n",
        "    solver.net.blobs['data'].data[...] = x_train[start:end]\n",
        "    solver.net.blobs['label'].data[...] = t_train[start:end]\n",
        "    solver.step(1)\n",
        "\n",
        "  train_acc, train_loss = test(solver.test_nets[0], x_train, t_train,\n",
        "                     tr_it_for_epoch, minibatch_size, num_class)\n",
        "  test_acc, _ = test(solver.test_nets[0], x_test, t_test,\n",
        "                     te_it_for_epoch, minibatch_size, num_class)\n",
        "  print(\"  Train loss: %.4f  Train acc: %.2f %%  Test acc: %.2f %%\" %\n",
        "        (train_loss, train_acc * 100, test_acc * 100))\n",
        "\n",
        "t_elapsed = time.time()-t_start\n",
        "print(\"---------------------------------------------\")\n",
        "print ('%d patterns (%.2f sec.) -> %.2f patt/sec' % \n",
        "       (x_train.shape[0]*n_epochs, t_elapsed, \n",
        "        x_train.shape[0]*n_epochs / t_elapsed))\n",
        "print(\"---------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Epoch 0  ......+++++++  Train loss: 0.0988  Train acc: 96.82 %  Test acc: 96.65 %\n",
            "Epoch 1  ......+++++++  Train loss: 0.0451  Train acc: 98.54 %  Test acc: 98.13 %\n",
            "---------------------------------------------\n",
            "120000 patterns (111.45 sec.) -> 1076.72 patt/sec\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "divl7TK36uPv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Extra] Define model and solver from Python\n",
        "\n",
        "Of course is it possible to define the network directly in Python as shown below. However we leave this part as optional for the reader to explore."
      ]
    },
    {
      "metadata": {
        "id": "U3du0nJhBFtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from caffe import layers as L\n",
        "from caffe import params as P\n",
        "from caffe.proto import caffe_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "def get_net(num_classes=10, train_mb_size=100):\n",
        "    \"\"\" Define net and return it as String \"\"\"\n",
        "\n",
        "    net = caffe.NetSpec()\n",
        "\n",
        "    net.data = L.Input(\n",
        "        shape=[dict(dim=[train_mb_size, 1, 28, 28, ])], ntop=1,\n",
        "        include=dict(phase=caffe.TRAIN)\n",
        "    )\n",
        "    net.test_data = L.Input(\n",
        "        shape=[dict(dim=[100, 1, 28, 28, ])], ntop=1,\n",
        "        include=dict(phase=caffe.TEST)\n",
        "    )\n",
        "    net.label = L.Input(\n",
        "        shape=[dict(dim=[train_mb_size])], ntop=1,\n",
        "        include=dict(phase=caffe.TRAIN)\n",
        "    )\n",
        "    net.test_label = L.Input(\n",
        "        shape=[dict(dim=[100])], ntop=1,\n",
        "        include=dict(phase=caffe.TEST)\n",
        "    )\n",
        "    net.conv1 = L.Convolution(\n",
        "        net.data, kernel_size=5,\n",
        "        num_output=32, param=[dict(lr_mult=1), dict(lr_mult=2)],\n",
        "        weight_filler=dict(type='xavier'),\n",
        "        bias_filler=dict(type='constant')\n",
        "    )\n",
        "    net.relu1 = L.ReLU(net.conv1, in_place=True)\n",
        "\n",
        "    net.conv2 = L.Convolution(\n",
        "        net.relu1, kernel_size=5,\n",
        "        num_output=32, param=[dict(lr_mult=1), dict(lr_mult=2)],\n",
        "        weight_filler=dict(type='xavier'),\n",
        "        bias_filler=dict(type='constant')\n",
        "    )\n",
        "    net.relu2 = L.ReLU(net.conv2, in_place=True)\n",
        "\n",
        "    net.fc1 = L.InnerProduct(\n",
        "        net.relu2, num_output=500,\n",
        "        param=[dict(lr_mult=1), dict(lr_mult=2)],\n",
        "        weight_filler=dict(type='xavier'),\n",
        "        bias_filler=dict(type='constant')\n",
        "    )\n",
        "    net.relu3 = L.ReLU(net.fc1, in_place=True)\n",
        "\n",
        "    net.out = L.InnerProduct(\n",
        "        net.fc1, num_output=num_classes,\n",
        "        param=[dict(lr_mult=1), dict(lr_mult=2)],\n",
        "        weight_filler=dict(type='xavier'),\n",
        "        bias_filler=dict(type='constant')\n",
        "    )\n",
        "\n",
        "    net.loss = L.SoftmaxWithLoss(net.out, net.label)\n",
        "    \n",
        "    net.accuracy = L.Accuracy(\n",
        "        net.out, net.test_label, include=dict(phase=caffe.TEST)\n",
        "    )\n",
        "\n",
        "    proto = str(net.to_proto())\n",
        "    proto = proto.replace('test_data', 'data').replace('test_label', 'label')\\\n",
        "        .replace('test_target', 'target')\n",
        "    \n",
        "    return proto\n",
        "\n",
        "def get_solver( net, base_lr, random_seed=1, lr_policy=\"step\", gamma=0.1,\n",
        "    stepsize=100000000, momentum=0.9, weight_decay=0.0005, test_iter=0,\n",
        "    test_interval=1000, display=20, solver_mode=caffe_pb2.SolverParameter.GPU):\n",
        "    \"\"\" Define solver and return it as String \"\"\"\n",
        "\n",
        "    solver_config = caffe_pb2.SolverParameter()\n",
        "\n",
        "    solver_config.random_seed = random_seed\n",
        "    solver_config.test_iter.append(1)\n",
        "    solver_config.test_interval = 1\n",
        "    solver_config.net = net\n",
        "    solver_config.base_lr = base_lr\n",
        "    solver_config.lr_policy = lr_policy\n",
        "    solver_config.gamma = gamma\n",
        "    solver_config.stepsize = stepsize\n",
        "    solver_config.momentum = momentum\n",
        "    solver_config.weight_decay = weight_decay\n",
        "    solver_config.snapshot_format = caffe_pb2.SolverParameter.HDF5\n",
        "    solver_config.solver_mode = solver_mode\n",
        "\n",
        "    solver_config = text_format.MessageToString(\n",
        "        solver_config, float_format='.6g'\n",
        "    )\n",
        "\n",
        "    return solver_config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9B6sNMJrWz6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net_name = \"net.prototxt\"\n",
        "\n",
        "with open(net_name, \"w\") as wf:\n",
        "  wf.write(get_net())\n",
        "  \n",
        "with open(solver_name, \"w\") as wf:\n",
        "  wf.write(get_solver(net_name, base_lr=0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MXpmO6SvDugP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Questions to explore:\n",
        "\n",
        "*   How to recover the weights of a particular layer?\n",
        "*   How to get the activations of a particular layer?\n",
        "*  How to cast a classifier into a Fully Convolutional Network?\n",
        "\n",
        "Some tips here: https://github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb\n"
      ]
    },
    {
      "metadata": {
        "id": "6fJMJm8j9av0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a ConvNet with Tensorflow\n",
        "\n",
        "Let us move to the second framework we are considering: *Tensorflow*. We don't need to install it since it's already pre-loaded in Google Colaboratory (guess why! :'D). So let us start by importing it and checking the version:"
      ]
    },
    {
      "metadata": {
        "id": "uLf5ypBbqXC8",
        "colab_type": "code",
        "outputId": "4fd47139-0715-4065-c753-cacd8dce8d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mW3BN4qPxvus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we can define directly the network structure using the tf.layers API:"
      ]
    },
    {
      "metadata": {
        "id": "eBpfVAMncKN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[minibatch_size, 1, 28, 28])\n",
        "t = tf.to_int64(tf.placeholder(tf.int32, shape=[minibatch_size]))\n",
        "\n",
        "# First Convolutional Layer\n",
        "x_image = tf.reshape(x, [-1,28,28,1])\n",
        "conv1 = tf.layers.conv2d(\n",
        "    x_image, 32, 5, strides=(1, 1), padding='valid', activation=tf.nn.relu\n",
        ")\n",
        "\n",
        "# Second Convolutional Layer\n",
        "conv2 = tf.layers.conv2d(\n",
        "    conv1, 32, 5, strides=(1, 1), padding='valid', activation=tf.nn.relu\n",
        ")\n",
        "pool2 = tf.layers.flatten(conv2)\n",
        "\n",
        "# Densely Connected Layer\n",
        "fc1 = tf.layers.dense(pool2, 500, name=\"fc1\", activation=tf.nn.relu)\n",
        "\n",
        "# Output Layer\n",
        "y_logits = tf.layers.dense(fc1, num_class, name=\"logits\")\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=t)\n",
        ")\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_logits,1), t)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "loss = tf.reduce_mean(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKfPKyiIx23V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As for caffe we can define the *test* function:"
      ]
    },
    {
      "metadata": {
        "id": "7iaAyAl5-CL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(x_set, y_set, test_iters, test_batch_size):\n",
        "    \"\"\" testing set accuracy: can be used for train and test\"\"\"\n",
        "    \n",
        "    accuracy_sum = 0.0\n",
        "    for it in range(test_iters):\n",
        "        if it % 100 == 1: print(\"+\", end=\"\", flush = True)\n",
        "        start = it * test_batch_size\n",
        "        end = (it + 1) * test_batch_size\n",
        "        accuracy_sum += sess.run(\n",
        "            fetches=accuracy,\n",
        "            feed_dict={x: x_set[start:end], t: y_set[start:end]}\n",
        "        )\n",
        "      \n",
        "    return accuracy_sum / test_iters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1wLJeyzx7sl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And then we can use the computational graph just created within an interactive session:"
      ]
    },
    {
      "metadata": {
        "id": "HkN-_fBuA2xY",
        "colab_type": "code",
        "outputId": "70437c71-2748-4a86-f494-548b68a9110d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "t_start = time.time()\n",
        "print(\"Start Training\")\n",
        "train_loss = 0\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"Epoch\", epoch, \" \", end=\"\")\n",
        "    for it in range(tr_it_for_epoch):\n",
        "        if it % 100 == 1: print(\".\", end=\"\", flush = True)\n",
        "        start = it * minibatch_size\n",
        "        end = (it + 1) * minibatch_size\n",
        "        batch_loss, _ = sess.run(\n",
        "            fetches=[loss, train_step],\n",
        "            feed_dict={x: x_train[start:end], t: t_train[start:end]}\n",
        "        )\n",
        "        train_loss += batch_loss\n",
        "\n",
        "    train_loss = train_loss / tr_it_for_epoch\n",
        "    train_acc = test(\n",
        "        x_train, t_train, tr_it_for_epoch, minibatch_size,\n",
        "    )  \n",
        "    test_acc = test(\n",
        "        x_test, t_test, te_it_for_epoch, minibatch_size,\n",
        "    )\n",
        "\n",
        "    print(\"  Train loss: %.4f  Train acc: %.2f %%  Test acc: %.2f %%\" %\n",
        "        (train_loss, train_acc * 100, test_acc * 100))\n",
        "    \n",
        "t_elapsed = time.time()-t_start\n",
        "print(\"---------------------------------------------\")\n",
        "print ('%d patterns (%.2f sec.) -> %.2f patt/sec' % \n",
        "       (x_train.shape[0]*n_epochs, t_elapsed, \n",
        "        x_train.shape[0]*n_epochs / t_elapsed))\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Epoch 0  ......+++++++  Train loss: 0.2569  Train acc: 97.35 %  Test acc: 97.35 %\n",
            "Epoch 1  ......+++++++  Train loss: 0.0741  Train acc: 98.50 %  Test acc: 98.29 %\n",
            "---------------------------------------------\n",
            "120000 patterns (23.82 sec.) -> 5038.38 patt/sec\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9ATgmZZk_D1v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Extra] Keras API"
      ]
    },
    {
      "metadata": {
        "id": "2lJFRqwkyTz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an bonus we leave to the reader the same implementation but using the keras API. Very easy, isn't it? But remember, with great abstraction power comes great responsibility..."
      ]
    },
    {
      "metadata": {
        "id": "BIxSi7BG9aUP",
        "colab_type": "code",
        "outputId": "977dcc5c-d056-4e10-80f7-09dd034b5751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.set_image_data_format('channels_first')\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(\n",
        "      32, (5, 5), strides=(1, 1), padding='valid', activation=tf.nn.relu\n",
        "  ),\n",
        "  tf.keras.layers.Conv2D(\n",
        "      32, (5, 5), strides=(1, 1), padding='valid', activation=tf.nn.relu\n",
        "  ),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(num_class, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "t_start = time.time()\n",
        "print(\"Start Training\")\n",
        "\n",
        "model.fit(x_train, t_train, batch_size=minibatch_size, epochs=n_epochs)\n",
        "model.evaluate(x_test, t_test)\n",
        "\n",
        "t_elapsed = time.time()-t_start\n",
        "print(\"---------------------------------------------\")\n",
        "print ('%d patterns (%.2f sec.) -> %.2f patt/sec' % \n",
        "       (x_train.shape[0]*n_epochs, t_elapsed, \n",
        "        x_train.shape[0]*n_epochs / t_elapsed))\n",
        "print(\"---------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1117 - acc: 0.9664\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0339 - acc: 0.9896\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "---------------------------------------------\n",
            "120000 patterns (24.83 sec.) -> 4831.94 patt/sec\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kKALvxrjFKWp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Questions to explore:\n",
        "\n",
        "*   What happens if you comment the first line of code?\n",
        "*   What if you also change the convolution padding from \"valid\" to \"same\"?\n",
        "\n",
        "Some tips here: https://keras.io/layers/convolutional/\n"
      ]
    },
    {
      "metadata": {
        "id": "yqPN1d1B7CcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a ConvNet with PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "hlT-5HvCy6x_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us delve now into the third and last framework we will consider: Pytorch. First of all let us install it and import it."
      ]
    },
    {
      "metadata": {
        "id": "JGRTfFMx7KAQ",
        "colab_type": "code",
        "outputId": "4519e1a9-2558-411a-ac70-4fc70428cb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' #'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print('Platform:', platform, 'Accelerator:', accelerator)\n",
        "\n",
        "!pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform: cp36-cp36m Accelerator: cu80\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5cce0000 @  0x7f81265492a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 0.0.1a1 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Torch 0.4.0 CUDA 8.0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GfSqaJK57MQI",
        "colab_type": "code",
        "outputId": "477bf0de-4f15-4559-8408-efba9291a2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "BilxjAkF8q9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# switch to False to use CPU\n",
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
        "torch.manual_seed(1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TR5Z55XN7Okg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rY3otyjd7TXG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   What's new in Pythorch 0.4?\n",
        "\n",
        "Some tips here: https://pytorch.org/blog/pytorch-0_4_0-migration-guide/\n"
      ]
    },
    {
      "metadata": {
        "id": "VD96_qvWzRt-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great! So now we can define the network and the independent forward function which can dynamically change depending on the input data:"
      ]
    },
    {
      "metadata": {
        "id": "s2N68j127TGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(512, 500)\n",
        "        self.fc2 = nn.Linear(500, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3t-0GmG0Pfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can define the test method as before:"
      ]
    },
    {
      "metadata": {
        "id": "c3BjalSR7QoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model, device, x_test, t_test, test_iters, test_batch_size):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for it in range(test_iters):\n",
        "        if it % 100 == 1: print(\"+\", end=\"\", flush = True)\n",
        "        start = it * test_batch_size\n",
        "        end = (it + 1) * test_batch_size\n",
        "        with torch.no_grad():\n",
        "            x = torch.from_numpy(x_test[start:end])\n",
        "            y = torch.from_numpy(t_test[start:end]).long()\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.cross_entropy(output, y).item() \n",
        "            # get the index of the max log-probability\n",
        "            pred = output.max(1, keepdim=True)[1] \n",
        "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    return correct / len(t_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpdEII350Wg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then finally define the model and start the training:"
      ]
    },
    {
      "metadata": {
        "id": "m-mvoCit7ycZ",
        "colab_type": "code",
        "outputId": "eaafffe6-2402-4439-d7de-b00c4f53c285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "model.train()\n",
        "\n",
        "t_start = time.time()\n",
        "print(\"Start Training\")\n",
        "train_loss = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"Epoch\", epoch, \" \", end=\"\")\n",
        "    train_loss = 0\n",
        "    for it in range(tr_it_for_epoch):\n",
        "        if it % 100 == 1: print(\".\", end=\"\", flush = True)\n",
        "        start = it * minibatch_size\n",
        "        end = (it + 1) * minibatch_size\n",
        "        x = torch.from_numpy(x_train[start:end])\n",
        "        y = torch.from_numpy(t_train[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x)\n",
        "        loss = F.cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss\n",
        "    \n",
        "    train_loss = train_loss / tr_it_for_epoch\n",
        "    train_acc = test(\n",
        "        model, device, x_train, t_train, tr_it_for_epoch, minibatch_size,\n",
        "    )  \n",
        "    test_acc = test(\n",
        "        model, device, x_test, t_test, te_it_for_epoch, minibatch_size,\n",
        "    )\n",
        "\n",
        "    print(\"  Train loss: %.4f  Train acc: %.2f %%  Test acc: %.2f %%\" %\n",
        "        (train_loss, train_acc * 100, test_acc * 100))\n",
        "    \n",
        "t_elapsed = time.time()-t_start\n",
        "print(\"---------------------------------------------\")\n",
        "print ('%d patterns (%.2f sec.) -> %.2f patt/sec' % \n",
        "       (x_train.shape[0]*n_epochs, t_elapsed, \n",
        "        x_train.shape[0]*n_epochs / t_elapsed))\n",
        "print(\"---------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Epoch 0  ......+++++++  Train loss: 0.3783  Train acc: 97.14 %  Test acc: 97.46 %\n",
            "Epoch 1  ......+++++++  Train loss: 0.0776  Train acc: 98.10 %  Test acc: 98.06 %\n",
            "---------------------------------------------\n",
            "120000 patterns (7.80 sec.) -> 15381.28 patt/sec\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V0zANlq470iZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wow! ~98% accuracy in such a short time.\n",
        "\n",
        "**Questions to explore:**\n",
        "\n",
        "*   Can you find a better parametrization to improve the final accuracy?\n",
        "*   Can you change the network architecture to improve the final accuracy?\n",
        "*   Can you achieve the same performances with a smaller architecture?\n",
        "*   What's the difference in accuracy if you change convolutions with fully connected layers?\n",
        "* Can you improve the speed of the training for all the frameworks described above?\n",
        "* What are the pros and cons of each framework in this simple example?\n",
        "\n",
        "Some tips here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"
      ]
    },
    {
      "metadata": {
        "id": "M8t8lqRa0lFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This concludes our little tour of the thre most used open-source frameworks for Deep Learning. Please make a PR if you spot any error or you want to contribute to the **ContinualAI-Colab** project! :-) "
      ]
    },
    {
      "metadata": {
        "id": "70Cpx9db8G9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Copyright (c) 2018. Continual AI. All rights reserved. **\n",
        "\n",
        "See the accompanying LICENSE file in the GitHub repository for terms. \n",
        "\n",
        "*Date: 27-11-2018                                                             \n",
        "Author: Vincenzo Lomonaco                                                    \n",
        "E-mail: contact@continualai.org                                           \n",
        "Website: continualai.org*              "
      ]
    }
  ]
}